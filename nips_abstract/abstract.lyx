#LyX 1.6.7 created this file. For more info see http://www.lyx.org/
\lyxformat 345
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{nips10submit_e,times}
\usepackage{microtype}
\nipsfinalcopy
\end_preamble
\use_default_options true
\language english
\inputencoding auto
\font_roman times
\font_sans default
\font_typewriter default
\font_default_family default
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\paperfontsize 10
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\cite_engine basic
\use_bibtopic false
\paperorientation portrait
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\author "" 
\author "" 
\end_header

\begin_body

\begin_layout Title
A Markov-Chain Monte Carlo Approach to Simultaneous Localization and Mapping
\end_layout

\begin_layout Author
Péter Torma
\begin_inset Newline newline
\end_inset

GusGus AB
\begin_inset Newline newline
\end_inset

Hungary
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
And
\end_layout

\end_inset

 András György
\begin_inset Newline newline
\end_inset

Machine Learning Res.
 Group
\begin_inset Newline newline
\end_inset

MTA SZTAKI, Hungary
\begin_inset Newline newline
\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
And
\end_layout

\end_inset

 Csaba Szepesvári, Roshan Shariff
\begin_inset Newline newline
\end_inset

Dept.
 of Computing Sciences
\begin_inset Newline newline
\end_inset

University of Alberta, Canada
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
thispagestyle{empty}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
As is well-acknowledged in the literature, Monte Carlo methods are sometimes
 non-trivial to set up.
 In this case study, we apply Markov-chain Monte Carlo (MCMC) techniques
 to the Bayesian version of the Simultaneous Localization and Mapping (SLAM)
 problem from robotics.
 The SLAM posterior over robot trajectories and landmark positions in an
 unknown environment has high dimensionality and can be multimodal and/or
 highly peaked, which makes it challenging to sample from.
 Thus the use of a simple Gibbs sampler, though shown to be possible in
 the literature, is highly inefficient.
 Assuming a prior distribution over the landmark positions, we present an
 efficient, provably consistent, and rapidly converging algorithm to sample
 from the SLAM posterior (for arbitrary dynamics and observation models)
 by representing it as the stationary distribution of a Markov process.
\end_layout

\begin_layout Standard
Previous SLAM algorithms either assume linearized models and Gaussian noise
 (e.g.
 EKF-SLAM) or use particle filters (e.g.
 FastSLAM).
 Since real-world robots usually have non-linear dynamics, the former approach
 may fail to converge.
 Particle filters approximate the posterior distribution over robot trajectories
 with a set of samples drawn from it.
 This fails when the certainty in the robot's position increases sharply,
 which happens when the robot observes a landmark it has seen earlier (
\begin_inset Quotes eld
\end_inset

a loop is closed
\begin_inset Quotes erd
\end_inset

) and is thus able to correct accumulated errors in its position.
 If no sample in the set lies close to the true trajectory, the particle
 set collapses to an inaccurate estimate.
\end_layout

\begin_layout Standard
The new algorithm constructs an 
\emph on
inference graph
\emph default
 in which the vertices represent robot and landmark locations.
 An assignment of values to the vertices induces a unique labeling of the
 edges, representing the geometric relationships between the vertex values.
 The many constraints, however, make most edge labelings inconsistent: the
 posterior is restricted to consistent labelings.
 By randomly selecting and resampling an edge label from a spanning tree
 of the graph, we are able to sample from a proposal distribution that maintains
 the consistency property.
 The robot dynamics and observation models, together with the observations
 and control inputs, assign a probability density to any labeling of the
 inference graph.
 We then use a generalized Metropolis-Hastings algorithm to sample a consistent
 edge labeling, from which the robot trajectory and landmark locations can
 be recovered.
 In the limit, the map and trajectory thus determined follow the SLAM posterior
 distribution.
 Since the graph stores the entire history of observations and controls,
 the edge resampling technique is able to correct errors arbitrarily far
 back in time, thereby successfully tracking the robot's position even after
 long loops have been closed.
\end_layout

\begin_layout Standard
We describe how the structure of the SLAM inference graph makes this edge
 resampling algorithm efficient, and suggest implementation strategies.
 Since the publication of the algorithm in 
\begin_inset CommandInset citation
LatexCommand cite
key "torma2010"

\end_inset

, we have improved its running time with a caching technique that exploits
 the nature of the SLAM problem.
 We have also run more experiments demonstrating that the resulting Markov
 process converges rapidly to the correct map and trajectory estimates.
 Thus MCMC methods allow the algorithm to solve the problem without compromising
 correctness or losing convergence guarantees.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintAll"
bibfiles "abstract"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
